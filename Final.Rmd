---
title: "697D-Final"
author: "Elaona Lemoto, Katherine (Yang) Liu"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(ggplot2)
library(dplyr)
library(ggforce)
library(tidyr)
library(readr)
library(purrr)
library(tidyverse)
```

** A description of the data preparation process.  
**-take aggregate of the variates
**-categorical, perhaps using the proportion instead
**-look at the medium of the entire category 
**-Take a weighted mean, weighted by the relative size of the counties.


##Introduction

Social determinants of health are defined as environmental factors, such as, where someone lives, where they go to school, work, and so forth, and how it affects a whole set of health outcomes and their overall quality of life. For instance, for folks who live in a middle class neighborhood might have higher access to grocery stores or farmers markets and a recreational facility, comparable to lower income neighborhoods that are found to have more fast food restaurants, less available grocery stores and more supercenters, and lack of recreational facilites. Social determinants of health is a growing field as more and more people are attempting to better understand how environmental factors impact one's health.

For this project in particular, we aim to study the social determinants of food security. We would like to look at how environmental factors like access to stores, proximity to stores, assistance for food by State, etc., impacts rates of food insecurity. What we currently understand about food insecurity is that it is not an isolated act. While income plays a part in one's ability to access food, there are several other variables that impact one’s security in having access to food. What the FDA proposed through the collection of these data is that different parts of a household's environment can impact their access to food. Therefore, the purpose of this project is to utilize the varying factors of one’s household in the geological, social, and economic sense from the variables outlined above, and uncover or magnify any measured impacts or explanation of a State’s percentage of households with food insecurity, with low food insecurity, and child food insecurity. 



##Data

In order to study this even further, we found data from the United States Department of Agriculture under their Economic Research Service. They published a dataset with over 275 variables, uniquely identified by FIPS county codes. For each county, they collected categories of data like Access, Health, Local Foods, and Price Taxes etc. Within these categories, this dataset contains several variables with comprehensive data on counts of households that have or do not have access to supermarkets, counts of store availability and whether it is within a walking distance of homes in that county, counts of fast food restaurant availability near home, counts of WIC redemptions, and number of local foods and farms, as well as variables concerning  socioeconomic status. Also included in this dataset were variables concerning food insecurity: household food insecurity, household low food insecurity, and child food insecurity, however, accounted for at the State and not FIPS county level. 

We have in total in this dataset 

###Data Distributions 
 


```{r}

hist(df$FOODINSEC_15_17)
hist(df$VLFOODSEC_15_17)
hist(df$CH_FOODINSEC_14_17)

```

##Research Questions

Using the data from the FDA, we are interested in measuring the varying geographic distance to resources, social net programs and assistance, and/or economic costs or barriers have any correlation with the aggregate percentage of households with food insecurity, households with low food security, and child food insecurity in at the State level.

A secondary question we would like to explore whether or not there are certain variables or factors that capture much of the variation we might see in our food insecurity variables.As mentioned above, the dataset created by the ERS department of the FDA has placed all of their variables in categories which we will use to create a factor analysis of food
insecurity. 

An additional possible question we would like to explore is whether a factor of socioeconomic status holds a significant impact on food insecurity. Redlining in the U.S. was a systematic discriminatory practice that divested from predominantly black and brown neighborhoods, therefore, we should expect to see a significance in socioeconomic demographics and food insecurity in the U.S.


##Method

In order to conduct this study, we will begin by conducting a multivariate
regression model with all of our predictor variables of interest and our three explained variables regarding food insecurity. Our predictor variables are:

- percent of population with low access to a stores in 2015
- percent of households with no car and low access to stores in 2015
- percent of SNAP households with low access to stores in 2015
- percent of children with low access to store in 2015
- percent of neighborhood that is white 
- percent of neighborhood that is black
- percent of neighborhood that is asian
- percent of neighborhood that is native american
- percent of neighborhood that is native hawaiian and pacific islander 
- percent of grocery stores per thousand people people in 2016
- percent of super centers per thousand people people
- percent of SNAP authorized stores for every ten thousand people
- percent of WIC authorized stores per thousand people
- percent of Fast food restaurants per thousand people in 2016
- percent of full service restaurants per thousand people in 2016
- percent of students eligible for reduced-price lunch in 2015
- percent of adults with obesity in 2017
- percent of Recreation & fitness facilities per thousand people in 2016

We will be interpeting the multivariate linear model function calculations in R. 
Included in this method will be simultaneous confidence intervals and predictor variables.

From here we will utilize the bootstrapping method for evaluating point estimates from R-squared. This will be done by creating bootstrap sample estimates for R-squared and then confidence intervals for R-squared based on the distribution of bootstrap distributions we simulate. Our second method with bootstrapping will be conducted by calculating the likelihood ratio test statistic of one of or more of our predictor variables and comparing it to the F distribution and the approximate chi-squared distribution. 

Another method we will be using from our course is conducting a factor analysis of our categories. This will implement our two last research questions regarding the categories of variables that the FDA’s dataset created as well as measuring whether certain factors do a better job of explaining the variation in food insecurity. 


##Results

Results for mlm test and simultanous CI and prediction intevals

Results of Factor analysis

Results for R-Squared Bootstarp

Results for Likelihood Ratio test Bootstrap

##Conclusion

```{r}
(df <- read_csv("final_data.csv"))
df<-df%>% 
  select(-FOODINSEC_12_14, -VLFOODSEC_12_14, -State, -CH_VLFOODSEC_14_17, -SNAPSPTH17)
n <- nrow(df)
```

*Brief summary of the data, variables

There are $n=150$ observations of the proxies for food insecurities
$z_1=$ FOODINSEC,     
$z_2=$ CH_FOODINSEC,      
$z_3=$ VLFOODSEC,   

and the ,   
$y_1=$ breaking length,    
$y_2=$ elastic modulus,   
$y_3=$ stress at failure,    
$y_4=$ burst strength.   

In order to conduct this study, we will begin by conducting a multivariate regression model with all of our predictor variables of interest and our three explained variables regarding food insecurity. Included in this method will be simultaneous confidence intervals for our predictor variables.
```{r}
# using the lm()
res <- lm(cbind(FOODINSEC_15_17, CH_FOODINSEC_14_17, VLFOODSEC_15_17) ~ ., data = df)
summary(res)

# Residuals:
head(resid(res))
# Fitted values:
head(fitted(res))
# Residual standard error:
sigma(res)
round(vcov(res), 2)
```

**** (I think this is incorrect, please take a look at the next chunk of code) 95% simultaneous confidence intervals 
```{r}
alpha <- 0.05

p <- 21
n <- nrow(df)

Y <- as.matrix(df %>% 
                 select(FOODINSEC_15_17,CH_FOODINSEC_14_17, VLFOODSEC_15_17))
               
(y_bar <- matrix(colMeans(Y), ncol = 1))

F_critical <- (p * (n - 1) / (n - p)) * qf(1 - alpha, p, n - p) 
s_d <- diag(cov(df))

CI_mat <-
  mapply(
    function(y_bar, s_d) y_bar + c(-1, 1) * sqrt(F_critical * s_d / n), 
    y_bar,
    s_d
    )
cat("Simultaneous confidence intervals:\n")
t(CI_mat)
```

Prediction intervals + confidence intervals
```{r}
alpha <- 0.05

Y <- as.matrix(df %>% select(20:22))
m <- ncol(Y) # number of responses
Z <- as.matrix(cbind(const = 1, df %>% select(1:19)))
r <- ncol(Z) - 1  # number of predictors (excluding constantn
b <- solve(t(Z) %*% Z) %*% t(Z) %*% Y

# new observation for predictors 
z0 <- 
  matrix(
    c(1,0.33, 0.5, 0.6),
    ncol=1, 
    dimnames = list(c("const", "HH_FINSEC", "VLHH_FINSEC", "CH_FINSEC"), NULL)
  )

#choose z0 that is meaningful 

# center
cntr <- t(b) %*% z0

# Prediction interval:
fctr_pred <- 
  sqrt(
    (1 + t(z0) %*% solve(t(Z) %*% Z,tol = 1e-19) %*% z0) * 
      (m * (n - r - 1) * qf(alpha, m, n - r - m, lower.tail = FALSE) / (n - r - m)))

a <- matrix(c(1, 0, 0, 0), ncol = 1)
half_CI <- (sqrt(t(a) %*% (estSigma * n / (n - r - 1)) %*% a)) * fctr_pred
pred_CI_Y1 <- c(t(a) %*%  cntr - half_CI, t(a) %*%  cntr + half_CI)
##### ****** Use mapply here? 

# Confidence interval: 
fctr <- 
  sqrt(
    (t(z0) %*% solve(t(Z) %*% Z) %*% z0) * 
      (m * (n - r - 1) * qf(alpha, m, n - r - m, lower.tail = FALSE) / (n - r - m)))
```



# Factor Analysis

```{r}
#Food Insecurity
df_f1 <- df %>% select(20:22)
R <- cor(df_f1)
eig <- eigen(R)
(Ltilde_m1 <- sqrt(eig$values[1]) * eig$vectors[ , 1, drop = F])

psi_tilde_m1 <- diag(R - Ltilde_m1 %*% t(Ltilde_m1))
Psi_tilde_m1 <- diag(psi_tilde_m1)
residual_matrix_m1 <- R - Ltilde_m1 %*% t(Ltilde_m1) - Psi_tilde_m1
(eig$values[1] / sum(eig$values))

#Access

df_f2 <- df %>% select(1:4,PCT_REDUCED_LUNCH15)
R2<- cor(df_f2)
eig2 <- eigen(R2)
(Ltilde_m2 <- sqrt(eig2$values[1]) * eig2$vectors[ , 1, drop = F])

psi_tilde_m2 <- diag(R2 - Ltilde_m2 %*% t(Ltilde_m2))
Psi_tilde_m2 <- diag(psi_tilde_m2)
residual_matrix_m2 <- R2 - Ltilde_m2 %*% t(Ltilde_m2) - Psi_tilde_m2
(eig2$values[1] / sum(eig2$values))


#Demographics
df_f3 <- df %>% select(5:10)
R3 <- cor(df_f3)
eig3 <- eigen(R3)
(Ltilde_m3 <- sqrt(eig3$values[1]) * eig3$vectors[ , 1, drop = F])

psi_tilde_m3 <- diag(R3 - Ltilde_m3 %*% t(Ltilde_m3))
Psi_tilde_m3 <- diag(psi_tilde_m3)
residual_matrix_m3 <- R3 - Ltilde_m3 %*% t(Ltilde_m3) - Psi_tilde_m3
(eig3$values[1] / sum(eig3$values))

#StoreAccess
df_f4 <- df %>% select(11:16)
R4 <- cor(df_f4)
eig4 <- eigen(R4)
(Ltilde_m4 <- sqrt(eig4$values[1]) * eig4$vectors[ , 1, drop = F])

psi_tilde_m4 <- diag(R4 - Ltilde_m4 %*% t(Ltilde_m4))
Psi_tilde_m4 <- diag(psi_tilde_m4)
residual_matrix_m4 <- R4 - Ltilde_m4 %*% t(Ltilde_m4) - Psi_tilde_m4
(eig4$values[1] / sum(eig4$values))

#Health

df_f5 <- df %>% select(PCT_OBESE_ADULTS17,RECFACPTH16)
R5 <- cor(df_f5)
eig5 <- eigen(R5)
(Ltilde_m5 <- sqrt(eig5$values[1]) * eig5$vectors[ , 1, drop = F])

psi_tilde_m5 <- diag(R5 - Ltilde_m5 %*% t(Ltilde_m5))
Psi_tilde_m5 <- diag(psi_tilde_m5)
residual_matrix_m5 <- R5 - Ltilde_m5 %*% t(Ltilde_m5) - Psi_tilde_m5
(eig5$values[1] / sum(eig5$values))
```

From here we will utilize the bootstrapping method for evaluating point estimates from R-squared. This will be done by creating bootstrap sample estimates for R-squared and then confidence intervals for R-squared based on the distribution of bootstrap distributions we simulate. Our second method with bootstrapping will be conducted by calculating the likelihood ratio test statistic of one of or more of our predictor variables and comparing it to the F distribution and the approximate chi-squared distribution.

#Bootstrapping
##Likelihood Ratio Test

```{r}
n <- nrow(df)

Y <- as.matrix(df %>% select(20:22))
m <- ncol(Y) # number of responses
Z <- as.matrix(cbind(const = 1, df %>% select(1:19)))
r <- ncol(Z) - 1  # number of predictors (excluding constant)

b <- solve(t(Z) %*% Z,tol = 1e-19) %*% t(Z) %*% Y
pred <- Z %*% b
resid <- Y - pred

b

variables_to_test <-  c("PCT_LACCESS_POP15", "PCT_LACCESS_HHNV15","PCT_LACCESS_SNAP15","LACCESS_CHILD15","GROCPTH16","SUPERCPTH16","PCT_NHWHITE10","PCT_NHBLACK10","PCT_HISP10","PCT_NHASIAN10","PCT_NHNA10","PCT_NHPI10","FFRPTH16","FSRPTH16","PCT_SNAP17", "PCT_OBESE_ADULTS17", "WICSPTH16", "RECFACPTH16")


variables_to_keep <- setdiff(colnames(Z), variables_to_test)
q <- length(variables_to_keep) - 1 # Not counting the intercept
grp1 <- rownames(b) %in% variables_to_keep
grp2 <- rownames(b) %in% variables_to_test

estSigma <- t(resid) %*% resid / n

b_grp1 <- solve(t(Z[ , grp1]) %*% Z[ , grp1]) %*% t(Z[ , grp1]) %*% Y
pred_grp1 <- Z[ , grp1] %*% b_grp1
resid_grp1 <- Y - pred_grp1

estSigma1 <- t(resid_grp1) %*% resid_grp1 / n

LR_test_statistic <- -n * (log(det(estSigma)) - log(det(estSigma1)))

# Approximate likelihood ratio test statistic:
approx_LR_test_statistic <- 
  -(n - r - 1 - 0.5 * (m - r + q + 1)) * (log(det(estSigma)) - log(det(estSigma1)))

# Reject?
ifelse(approx_LR_test_statistic > qchisq(0.95, m * (r - q)), "Reject H0", "Don't reject H0")

W <- det(estSigma) / det(estSigma1)

h <- length(variables_to_test)  
# h = q' = r - q; see corrected slide 25 in notes for Chapter 7

d1 <- (n - r - 1) - 0.5 * (m - h + 1)
d2 <- (m * h - 2)/4
d3 <- m^2 + h^2 - 5
d3 <- if (d3 > 0) { 
  sqrt(((m * h)^2 - 4) / d3)
} else { 1 }

F_approx_stat <- ((W^(-1 / d3) - 1) * (d1 * d3 - 2 * d2)) / (m  * h)

# The corresponding p-value is:
pf(F_approx_stat, m * h, d1 * d3 - 2 * d2, lower.tail = FALSE)


# Bootstrap study:
n <- nrow(df)

S <- 10000
LR_stat_sample <- numeric(S)

s <- 1
while (s <= S) {
  try({
    bootstrap_sample_idx <- sample(n, replace = TRUE)
    bstp_df <- df[bootstrap_sample_idx, ]
    
    Y <- as.matrix(bstp_df %>% select(20:22))
    m <- ncol(Y)
    
    variables_to_test <- c("PCT_LACCESS_POP15", "PCT_LACCESS_HHNV15","PCT_LACCESS_SNAP15","LACCESS_CHILD15","GROCPTH16","SUPERCPTH16","PCT_NHWHITE10","PCT_NHBLACK10","PCT_HISP10","PCT_NHASIAN10","PCT_NHNA10","PCT_NHPI10","FFRPTH16","FSRPTH16","PCT_SNAP17", "PCT_OBESE_ADULTS17", "WICSPTH16", "RECFACPTH16")

    variables_to_keep <- setdiff(colnames(Z), variables_to_test)
    grp1 <- rownames(b) %in% variables_to_keep
    grp2 <- rownames(b) %in% variables_to_test
    
    Z <- as.matrix(cbind(const = 1, bstp_df %>% select(1:19)))
    
    Z[ , grp2] <- Z[sample(nrow(Z)), grp2]   # shuffle rows of tested predictors
    
    r <- ncol(Z) - 1
    
    b <- solve(t(Z) %*% Z, tol = 2.05722e-18) %*% t(Z) %*% Y
    pred <- Z %*% b
    resid <- Y - pred
    
    estSigma <- t(resid) %*% resid / n
    
    b_grp1 <- solve(t(Z[ , grp1]) %*% Z[ , grp1]) %*% t(Z[ , grp1]) %*% Y
    estSigma1 <- t(Y - Z[ , grp1] %*% b_grp1) %*% (Y - Z[ , grp1] %*% b_grp1) / n
    
    LR_stat_sample[s] <- det(estSigma) / det(estSigma1)
    s <- s + 1
  })
}

# p-value for bootstrap sample:
sum( LR_stat_sample < W ) / S

```
#Use HW 7 code 